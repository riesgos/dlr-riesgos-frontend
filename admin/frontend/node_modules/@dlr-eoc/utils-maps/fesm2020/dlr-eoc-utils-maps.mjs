import LayerGroup from 'ol/layer/Group';
import { unByKey } from 'ol/Observable';
import LayerRenderer from 'ol/renderer/Layer';
import ImageLayer from 'ol/layer/Image';
import { transformExtent } from 'ol/proj';
import CanvasVectorLayerRenderer from 'ol/renderer/canvas/VectorLayer';
import VectorLayer from 'ol/layer/Vector';
import { Cluster } from 'ol/source';
import { replaceChildren } from 'ol/dom';
import Delaunator from 'delaunator';

function flattenLayers(layers) {
    let flattenedLayers = [];
    for (const layer of layers) {
        if (layer instanceof LayerGroup) {
            const subLayers = layer.getLayers().getArray();
            const flattenedSubLayers = flattenLayers(subLayers);
            flattenedLayers = Array.prototype.concat(flattenedLayers, flattenedSubLayers);
        }
        else {
            // this cast is ok: since `layer` is no LayerGroup, it must be a Layer.
            // See the `Subclasses` section here: https://openlayers.org/en/latest/apidoc/module-ol_layer_Base-BaseLayer.html
            flattenedLayers.push(layer);
        }
    }
    return flattenedLayers;
}
/** Experimental: This is an experimental technology Check the Browser compatibility table carefully before using this in production. */
/**
 * Merges all layers of a map into one canvas image.
 * Assumes that the ``targetCanvas`` has the same size as the map! If it doesn't, use `scaledMapToSingleCanvas` instead.
 * Create a target-canvas of an appropriate size.
 *  1. Trigger a layer-re-render.
 *  2. For each layer, we capture the 'postrender' event ...
 *  3. ... and copy the canvas-bitmap into the target.
 *
 * Note: if the user moves the original map while the render-process is still ongoing, this can distort the output.
 * We would suggest to deactivate user-interactions until the 'onDone' callback has been received.
 *
 * Note also: Before passing the canvas, set its drawing-buffer size: `canvas.width` and `canvas.height`.
 * This is the size of the actually drawn image in pixels.
 * Note that this value may differ from clientWidth/clientHeight: that is the size to which the actual image is scaled to in the DOM.
 */
function mapToSingleCanvas(map, targetCanvas, onDone, keepSynced = false) {
    // Step 0: inspecting targetCanvas
    const targetContext = targetCanvas.getContext('2d');
    if (!targetContext) {
        throw new Error('The target-canvas needs to use a 2d-context.');
    }
    if (!targetCanvas.width || !targetCanvas.height) {
        throw new Error('TargetCanvas: width or height have not been set.');
    }
    targetContext.clearRect(0, 0, targetCanvas.width, targetCanvas.height);
    const mapSize = map.getSize();
    const mapResolution = map.getView().getResolution();
    targetCanvas.width = mapSize[0];
    targetCanvas.height = mapSize[1];
    const layers = flattenLayers(map.getLayers().getArray());
    const subscriptions = [];
    for (const layer of layers) {
        if (layer.getVisible() && layer.getOpacity() > 0.0) {
            // Step 2: catch each layer's postrender event.
            // Note that ol/renderer/webgl/* does not call `this.postRender(context, frameState)`
            // in `renderFrame` - so heatmaps won't be copied here!
            const key = layer.on('postrender', (event) => {
                const sourceContext = event.context;
                const sourceCanvas = sourceContext.canvas;
                // Step 3: copy source bitmap to target-canvas.
                targetContext.drawImage(sourceCanvas, 0, 0, sourceCanvas.clientWidth, sourceCanvas.clientHeight, 0, 0, targetCanvas.width, targetCanvas.height);
            });
            if (Array.isArray(key)) {
                key.map(k => subscriptions.push(k));
            }
            else {
                subscriptions.push(key);
            }
        }
    }
    if (keepSynced) {
        map.on('rendercomplete', (evt) => {
            onDone(targetCanvas);
        });
    }
    else {
        // if we don't want the canvas to remain in sync with the map, we unsubscribe to further changes here.
        map.once('rendercomplete', (evt) => {
            // note that a map-render-event does not have a context ... contrary to a layer-render-event.
            for (const key of subscriptions) {
                unByKey(key);
            }
            onDone(targetCanvas);
        });
    }
    // Step 1: trigger a re-render of the map.
    map.renderSync();
}
/**
 * Copies a map's layers onto a single canvas.
 * For this, we ...
 *  1. Update the original map's size to match the target-canvas.
 *  2. Get an image of the scaled map
 *  3. Reset the map's dimensions to the initial values.
 *
 * Note: if the user moves the original map while the render-process is still ongoing, this can distort the output.
 * We would suggest to deactivate user-interactions until the 'done' callback has been received.
 *
 * Note also: Before passing the canvas, set its drawing-buffer size: `canvas.width` and `canvas.height`.
 * This is the size of the actually drawn image in pixels.
 * Note that this value may differ from clientWidth/clientHeight: that is the size to which the actual image is scaled to in the DOM.
 */
function scaledMapToSingleCanvas(map, targetCanvas, onDone, keepSynced = false) {
    /* An alternative approach would be to create a new map with the desired size and copies of the old map's layers.
     * This way we wouldn't have to mess with the original map's size.
     * But unfortunately openlayers provides no means of cloning a layer.
     * I could not find one, either: neither of JSON.parse, lodash.cloneDeep, ramda.clone or rfdc works here.
     */
    // Step 1: adjust map-size to match targetCanvas.
    const initialMapSize = map.getSize();
    const initialMapResolution = map.getView().getResolution();
    map.setSize([targetCanvas.width, targetCanvas.height]);
    const scale = Math.min(targetCanvas.width / initialMapSize[0], targetCanvas.height / initialMapSize[1]);
    map.getView().setResolution(initialMapResolution / scale);
    // Step 2: get image of scaled map
    mapToSingleCanvas(map, targetCanvas, (updatedTargetCanvas) => {
        // Step 3: set map-size back to initial values.
        map.setSize(initialMapSize);
        map.getView().setResolution(initialMapResolution);
        onDone(updatedTargetCanvas);
    }, keepSynced);
}
/**
 * A comfort-function for getting a snapshot of a map into a canvas.
 * Halts all map-interactions to prevent the user from panning the map during rendering.
 * Sets the canvas' internal drawing-buffer-size: this way, the canvas' contents can be exported
 * in the drawing-buffer-size, which may differ from the display-size (the latter is set by the DOM/CSS).
 *
 * Example usage:
 * ```
 *   previewButton.addEventListener('click', () => {
 *   simpleMapToCanvas(map, previewCanvas, paper.widthPx, paper.heightPx, (updated) => {
 *       console.log('done');
 *   });
 *   downloadButton.addEventListener('click', () => {
 *      downloadUrl(previewCanvas.toDataURL('image/png'), 'full');
 *   });
 * ```
 */
function simpleMapToCanvas(map, targetCanvas, drawingBufferWidth, drawingBufferHeight, onDone, keepSynced = false) {
    // Halting interactions: prevents user from panning map during drawing process.
    const interactions = map.getInteractions();
    interactions.forEach((interaction) => {
        interaction.setActive(false);
    });
    if (drawingBufferHeight && drawingBufferWidth) {
        // Before passing the canvas, set its drawing-buffer size: `canvas.width` and `canvas.height`.
        // This is the size of the actually drawn image in pixels.
        // Note that this value may differ from clientWidth/clientHeight:
        // that is the size to which the actual image is scaled to in the DOM.
        targetCanvas.width = drawingBufferWidth;
        targetCanvas.height = drawingBufferHeight;
    }
    scaledMapToSingleCanvas(map, targetCanvas, (updatedCanvas) => {
        // reactivating interactions
        interactions.forEach((interaction) => {
            interaction.setActive(true);
        });
        if (onDone) {
            onDone(updatedCanvas);
        }
    }, keepSynced);
}

const flattenRecursive = (m) => {
    let flat = [];
    for (const row of m) {
        let flattenedRow;
        if (Array.isArray(row[0])) {
            flattenedRow = flattenRecursive(row);
        }
        else {
            flattenedRow = row;
        }
        flat = Array.prototype.concat(flat, flattenedRow);
    }
    return flat;
};
const createNDimArray = (dimensions) => {
    if (dimensions.length > 0) {
        const dim = dimensions[0];
        const rest = dimensions.slice(1);
        const newArray = new Array(dim);
        for (let i = 0; i < dim; i++) {
            newArray[i] = createNDimArray(rest);
        }
        return newArray;
    }
    else {
        return undefined;
    }
};
const logN = (val, root) => {
    return Math.log(val) / Math.log(root);
};
const isPowerOf = (val, root) => {
    return logN(val, root) % 1 === 0;
};
const nextPowerOf = (val, root) => {
    const exponent = Math.ceil(logN(val, root));
    return Math.pow(2, exponent);
};

/**
 * WEBGL
 *
 * A rasterization engine that allows to draw points, line segments, or triangles.
 *
 * Vertex shaders take whatever coordinates you use and return a 3-d array with elements between -1 and 1.
 * Basically, this is a 3d-array, but WebGl does not use the z-axis for real perspective, but only to differentiate
 * what pixel lies in front of another.
 * This is not like looking in a 3d-box, but rather like looking on multiple stacked sheets on a projector.
 * Actually, this is a lie. WebGl uses 4 coordinates: x, y, z and w. The above only holds if you keep w at 1.
 * After applying the vertex shader, WebGl divides all coordinates by w, yielding (x/w, y/w, z/w, 1).
 * This can be used to calculate projections - google for 'homogeneous coordinates' to find out more.
 * Compare this [site](https://www.tomdalling.com/blog/modern-opengl/explaining-homogenous-coordinates-and-projective-geometry/)
 * and the shader `basic3d.vert.glsl`.
 *
 * WebGL knows two data structures:
 *  - buffers (generic byte arrays): usually positions, normals, texture-coordinates, vertex-colors etc.
 *    buffers are accessed in shaders as 'attributes'.
 *    note that buffers contain one entry for each vertex.
 *  - textures (bitmap images).
 *
 * Shaders use these data structures in two different ways.
 *  - Attributes are values, one per vertex.
 *    For the shader, attributes are read-only.
 *    Attributes default to [0, 0, 0, 1]
 *  - Uniforms are values, one per shader.
 *    For the shader, uniforms are read-only.
 *
 * Apart from this, shaders know about two more types of data:
 *  - Varyings are values that are passed from vertex-shader to fragment-shader.
 *    They are read-only only for the fragment-shader.
 *  - Const: a compile-time constant.
 *
 * A program is just a list of compiled and linked vertex- and fragment-shaders.
 *
 *
 * Drawing: there's drawArrays and drawElements.
 *  - drawArrays is the robust all-rounder.
 *  - drawElements can be more performant if you share vertices between objects.
 *
 *
 * Rendering data is fast, but uploading it into GPU memory is slow.
 * Optimizing WebGl performance mostly means: Avoiding having GPU and CPU wait for each other.
 * The more the GPU can do in bulk, the better. The more often you have to upload data from CPU to GPU, the worse.
 *  - So avoid switching programs, buffers and uniforms if you can.
 *    (You won't be able to avoid switching buffers, because every object is likely different. But sort your objects by their shaders, and you'll save a lot of time.)
 *  - Try to do translations, rotations and shears inside the vertex-shader instead of altering the object's buffer.
 *  - If appropriate, create über-shaders and über-buffers, that contain information for more than just one object.
 *
 * There is another thing that affects performance:
 * WebGL will only run fragment-shaders when the object's pixels aren't already obscured by a larger object in front of it.
 * That means it makes sense to first draw large objects that are close to the camera - all objects behind them won't need their fragment-shader executed.
 *
 * All `create*` functions unbind variables after setting their values. This is to avoid unwanted side-effects.
 *
 *
 *
 * WebGL components
 *    - global-state
 *        - ARRAY_BUFFER_BINDING: currently bound buffer
 *        - VERTEX_ARRAY_BINDING: currently bound vertex-array (in WebGL 1 this was always only the global vertex-array, in WebGL 2 you can now create your own ones)
 *        - ACTIVE_TEXTURE: currently bound texture
 *        - texture-units: a list of pointers to texture-buffers.
 *        - uniform-buffer-bindings (WebGL2 only): a list of pointers to uniform-buffers.
 *    - vertex-array: a list of pointers to attribute-buffers (+ metadata like datatype, stride, offset etc.).
 *        - all attributes must have the same number of elements (though one attribute's elements may be vec2's, while another one's may be vec3's)
 *        - drawArray: attributes repeat elements in groups of three for drawing triangles
 *        - drawElements: the indices for the triangles are defined in ELEMENT_ARRAY_BUFFER_BINDING
 *        - WebGL 2.0: allows you to create your own vertex-arrays, whereas 1.0 always only used one global vertex-array.
 */
const shaderInputTextureBindPoint = 0;
const textureConstructionBindPoint = 7;
/**
 * Compile shader.
 */
const compileShader = (gl, typeBit, shaderSource) => {
    const shader = gl.createShader(typeBit);
    if (!shader) {
        throw new Error('No shader was created');
    }
    gl.shaderSource(shader, shaderSource);
    gl.compileShader(shader);
    if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
        gl.deleteShader(shader);
        throw new Error(`An error occurred compiling the shader: ${gl.getShaderInfoLog(shader)}.    \n\n Shader code: ${shaderSource}`);
    }
    return shader;
};
/**
 * Note that every program *must* have one and only one vertex-shader
 * and one and only one fragment shader.
 * That means you cannot add multiple fragment-shaders in one program. Instead, either load them in consecutively as part of different programs,
 * or generate an über-shader that contains both codes.
 */
const createShaderProgram = (gl, vertexShaderSource, fragmentShaderSource) => {
    const program = gl.createProgram();
    if (!program) {
        throw new Error('No program was created');
    }
    const vertexShader = compileShader(gl, gl.VERTEX_SHADER, vertexShaderSource);
    const fragmentShader = compileShader(gl, gl.FRAGMENT_SHADER, fragmentShaderSource);
    gl.attachShader(program, vertexShader);
    gl.attachShader(program, fragmentShader);
    gl.linkProgram(program);
    gl.detachShader(program, vertexShader);
    gl.detachShader(program, fragmentShader);
    gl.deleteShader(vertexShader);
    gl.deleteShader(fragmentShader);
    if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
        gl.deleteProgram(program);
        throw new Error('Unable to initialize the shader program: ' + gl.getProgramInfoLog(program));
    }
    return program;
};
const setup3dScene = (gl) => {
    gl.viewport(0, 0, gl.canvas.width, gl.canvas.height);
    gl.enable(gl.DEPTH_TEST);
    gl.depthFunc(gl.LEQUAL);
    gl.cullFace(gl.BACK);
    clearBackground(gl, [0, 0, 0, 1]);
};
const updateViewPort = (gl, x0, y0, x1, y1) => {
    gl.viewport(x0, y0, x1, y1);
};
const bindProgram = (gl, program) => {
    gl.useProgram(program);
};
const clearBackground = (gl, color) => {
    gl.clearColor(color[0], color[1], color[2], color[3]);
    gl.clearDepth(1.0);
    gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);
};
/**
 * Create buffer. Creation is slow! Do *before* render loop.
 */
const createFloatBuffer = (gl, data, drawingMode = gl.TRIANGLES) => {
    const dataFlattened = new Float32Array(flattenRecursive(data));
    const buffer = gl.createBuffer();
    if (!buffer) {
        throw new Error('No buffer was created');
    }
    gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
    gl.bufferData(gl.ARRAY_BUFFER, dataFlattened, gl.STATIC_DRAW);
    // STATIC_DRAW: tells WebGl that we are not likely to change this data much.
    gl.bindBuffer(gl.ARRAY_BUFFER, null); // unbinding
    const bufferObject = {
        buffer: buffer,
        vectorSize: data[0].length,
        vectorCount: data.length,
        type: gl.FLOAT,
        normalize: false,
        stride: 0,
        offset: 0,
        drawingMode: drawingMode
    };
    return bufferObject;
};
const drawArray = (gl, bo) => {
    gl.drawArrays(bo.drawingMode, bo.offset, bo.vectorCount);
};
const updateBufferData = (gl, bo, newData) => {
    const dataFlattened = new Float32Array(flattenRecursive(newData));
    gl.bindBuffer(gl.ARRAY_BUFFER, bo.buffer);
    gl.bufferData(gl.ARRAY_BUFFER, dataFlattened, gl.STATIC_DRAW);
    gl.bindBuffer(gl.ARRAY_BUFFER, null); // unbinding
    const newBufferObject = {
        buffer: bo.buffer,
        vectorSize: newData[0].length,
        vectorCount: newData.length,
        type: gl.FLOAT,
        normalize: false,
        stride: 0,
        offset: 0,
        drawingMode: bo.drawingMode,
    };
    return newBufferObject;
};
/**
 * Fetch attribute's location (attribute declared in some shader). Slow! Do *before* render loop.
 */
const getAttributeLocation = (gl, program, attributeName) => {
    const loc = gl.getAttribLocation(program, attributeName);
    if (loc === -1) {
        throw new Error(`Couldn't find attribute ${attributeName} in program.`);
    }
    return loc;
};
/**
 * Attributes vary from vertex to vertex - that means that there are *many* of them.
 * So it makes sense for WebGl to store attribute values in a dedicated data structure - the buffer.
 */
const bindBufferToAttribute = (gl, attributeLocation, bufferObject) => {
    // Bind buffer to global-state ARRAY_BUFFER
    gl.bindBuffer(gl.ARRAY_BUFFER, bufferObject.buffer);
    // Enable editing of vertex-array-location
    gl.enableVertexAttribArray(attributeLocation);
    // Bind the buffer currently at global-state ARRAY_BUFFER to a vertex-array-location.
    gl.vertexAttribPointer(attributeLocation, bufferObject.vectorSize, bufferObject.type, bufferObject.normalize, bufferObject.stride, bufferObject.offset);
    // gl.disableVertexAttribArray(attributeLocation); <-- must not do this!
};
const createIndexBuffer = (gl, indices, drawingMode = gl.TRIANGLES) => {
    const indicesFlattened = new Uint16Array(flattenRecursive(indices));
    const buffer = gl.createBuffer();
    if (!buffer) {
        throw new Error('No buffer was created');
    }
    gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, buffer);
    gl.bufferData(gl.ELEMENT_ARRAY_BUFFER, indicesFlattened, gl.STATIC_DRAW);
    gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, null);
    const bufferObject = {
        buffer: buffer,
        count: indicesFlattened.length,
        type: gl.UNSIGNED_SHORT,
        offset: 0,
        drawingMode: drawingMode
    };
    return bufferObject;
};
const bindIndexBuffer = (gl, ibo) => {
    gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, ibo.buffer);
};
const drawElements = (gl, ibo) => {
    gl.drawElements(ibo.drawingMode, ibo.count, ibo.type, ibo.offset);
};
/**
 * A shader's attributes get their buffer-values from the VERTEX_ARRAY, but they are constructed in the ARRAY_BUFFER.
 * Textures analogously are served from the TEXTURE_UNITS, while for construction they are bound to ACTIVE_TEXTURE.
 *
 * There is a big difference, however. Contrary to buffers which receive their initial value while still outside the ARRAY_BUFFER,
 * a texture does already have to be bound into the TEXTURE_UNITS when it's being created.
 * Since it'll always be bound into the slot that ACTIVE_TEXTURE points to, you can inadvertently overwrite another texture that is
 * currently in this place. To avoid this, we provide a dedicated `textureConstructionBindPoint`.
 *
 * Buffers are easier in this, since with vertexAttribPointer we are guaranteed to get a slot in the VERTEX_ARRAY that is not
 * already occupied by another buffer.
 */
const createTexture = (gl, image) => {
    const texture = gl.createTexture(); // analog to createBuffer
    if (!texture) {
        throw new Error('No texture was created');
    }
    gl.activeTexture(gl.TEXTURE0 + textureConstructionBindPoint); // so that we don't overwrite another texture in the next line.
    gl.bindTexture(gl.TEXTURE_2D, texture); // analog to bindBuffer. Binds texture to currently active texture-bindpoint (aka. texture unit).
    const level = 0;
    const internalFormat = gl.RGBA;
    const format = gl.RGBA;
    const type = gl.UNSIGNED_BYTE;
    gl.texImage2D(gl.TEXTURE_2D, level, internalFormat, format, type, image); // analog to bufferData
    gl.generateMipmap(gl.TEXTURE_2D); // mipmaps are mini-versions of the texture.
    gl.bindTexture(gl.TEXTURE_2D, null); // unbinding
    let w, h;
    if (image instanceof HTMLImageElement) {
        w = image.naturalWidth;
        h = image.naturalHeight;
    }
    else {
        w = image.width;
        h = image.height;
    }
    const textureObj = {
        texture: texture,
        level: level,
        internalformat: internalFormat,
        format: format,
        type: type,
        width: w,
        height: h,
        border: 0
    };
    return textureObj;
};
/**
 * This is just another texture, but optimized for carrying data, not for display.
 *
 * Valid combinations of texture-data parameters:
 *
 * | Internal Format | Format          | Type                      | Source Bytes Per Pixel |
 * |-----------------|-----------------|---------------------------|------------------------|
 * | RGBA            | RGBA            | UNSIGNED_BYTE             | 4                      |
 * | RGB	         | RGB             | UNSIGNED_BYTE             | 3                      |
 * | RGBA            | RGBA            | UNSIGNED_SHORT_4_4_4_4    | 2                      |
 * | RGBA            | RGBA            | UNSIGNED_SHORT_5_5_5_1	   | 2                      |
 * | RGB             | RGB             | UNSIGNED_SHORT_5_6_5      | 2                      |
 * | LUMINANCE_ALPHA | LUMINANCE_ALPHA | UNSIGNED_BYTE	           | 2                      |
 * | LUMINANCE       | LUMINANCE       | UNSIGNED_BYTE             | 1                      |
 * | ALPHA           | ALPHA           | UNSIGNED_BYTE             | 1                      |
 * Plus many more in WebGL2.
 *
 */
const createDataTexture = (gl, data) => {
    const height = data.length;
    const width = data[0].length;
    const channels = data[0][0].length;
    if (!isPowerOf(width, 2) || !isPowerOf(height, 2)) {
        throw new Error(`Texture-data-dimensions must be a power of two, but are ${width} x ${height}`);
    }
    if (channels !== 4) {
        // @todo: remove this when we implement non-rgba data-textures.
        throw new Error(`Expecting 4 channels, but ${channels} provided`);
    }
    const texture = gl.createTexture(); // analog to createBuffer
    if (!texture) {
        throw new Error('No texture was created');
    }
    gl.activeTexture(gl.TEXTURE0 + textureConstructionBindPoint); // so that we don't overwrite another texture in the next line.
    gl.bindTexture(gl.TEXTURE_2D, texture); // analog to bindBuffer. Binds texture to currently active texture-bindpoint (aka. texture unit).
    // to be used for data. we want no interpolation of data, so disallow mipmap and interpolation.
    const level = 0;
    const border = 0;
    const internalFormat = gl.RGBA;
    const format = gl.RGBA;
    const type = gl.UNSIGNED_BYTE;
    const binData = new Uint8Array(flattenRecursive(data));
    if (channels !== 4) {
        // have WebGL digest data one byte at a time.
        // (Per default tries 4 bytes at a time, which causes errors when our data is not a mulitple of 4).
        const alignment = 1; // valid values are 1, 2, 4, and 8.
        gl.pixelStorei(gl.UNPACK_ALIGNMENT, alignment);
    }
    gl.texImage2D(gl.TEXTURE_2D, level, internalFormat, width, height, border, format, type, binData); // analog to bufferData
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
    gl.bindTexture(gl.TEXTURE_2D, null); // unbinding
    const textureObj = {
        texture: texture,
        level: level,
        internalformat: internalFormat,
        format: format,
        type: type,
        width: width,
        height: height,
        border: border
    };
    return textureObj;
};
const createEmptyTexture = (gl, width, height) => {
    if (width <= 0 || height <= 0) {
        throw new Error('Width and height must be positive.');
    }
    const texture = gl.createTexture();
    if (!texture) {
        throw new Error('No texture was created');
    }
    gl.activeTexture(gl.TEXTURE0 + textureConstructionBindPoint); // so that we don't overwrite another texture in the next line.
    gl.bindTexture(gl.TEXTURE_2D, texture);
    gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, width, height, 0, gl.RGBA, gl.UNSIGNED_BYTE, null);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
    gl.bindTexture(gl.TEXTURE_2D, null);
    const textureObj = {
        texture: texture,
        level: 0,
        internalformat: gl.RGBA,
        format: gl.RGBA,
        type: gl.UNSIGNED_BYTE,
        width: width,
        height: height,
        border: 0
    };
    return textureObj;
};
/**
 * Even though we reference textures as uniforms in a fragment shader, assigning an actual texture-value to that uniform works differently from normal uniforms.
 * Normal uniforms have a concrete value.
 * Texture uniforms, on the other hand, are just an integer-index that points to a special slot in the GPU memory (the bindPoint) where the actual texture value lies.
 */
const bindTextureToUniform = (gl, texture, bindPoint, uniformLocation) => {
    if (bindPoint > gl.getParameter(gl.MAX_COMBINED_TEXTURE_IMAGE_UNITS)) {
        throw new Error(`There are only ${gl.getParameter(gl.MAX_COMBINED_TEXTURE_IMAGE_UNITS)} texture bind points, but you tried to bind to point nr. ${bindPoint}.`);
    }
    if (bindPoint === textureConstructionBindPoint) {
        console.error(`You are about to bind to the dedicated texture-construction bind point (nr. ${bindPoint}).
        If after this call another texture is built, your shader will now use that new texture instead of this one!
        Consider using another bind point.`);
    }
    gl.activeTexture(gl.TEXTURE0 + bindPoint); // analog to enableVertexAttribArray
    gl.bindTexture(gl.TEXTURE_2D, texture); // analog to bindBuffer. Binds texture to currently active texture-bindpoint (aka. texture unit).
    gl.uniform1i(uniformLocation, bindPoint); // analog to vertexAttribPointer
};
const updateTexture = (gl, to, newData) => {
    gl.activeTexture(gl.TEXTURE0 + textureConstructionBindPoint); // so that we don't overwrite another texture in the next line.
    gl.bindTexture(gl.TEXTURE_2D, to.texture); // analog to bindBuffer. Binds texture to currently active texture-bindpoint (aka. texture unit).
    if (newData instanceof HTMLImageElement || newData instanceof HTMLCanvasElement) {
        gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, newData); // analog to bufferData
    }
    else {
        const width = newData[0].length;
        const height = newData.length;
        if (!isPowerOf(width, 2) || !isPowerOf(height, 2)) {
            throw new Error(`Texture-data-dimensions must be a power of two, but are ${height} x ${width}`);
        }
        const binData = new Uint8Array(flattenRecursive(newData)); // @todo: use another ArrayBufferView depending on to.format?
        gl.texImage2D(gl.TEXTURE_2D, to.level, to.internalformat, to.width, to.height, to.border, to.format, to.type, binData);
    }
    gl.generateMipmap(gl.TEXTURE_2D); // mipmaps are mini-versions of the texture.
    gl.bindTexture(gl.TEXTURE_2D, null); // unbinding
    if (newData instanceof HTMLImageElement) {
        to.width = newData.naturalWidth;
        to.height = newData.naturalHeight;
    }
    else if (newData instanceof HTMLCanvasElement) {
        to.width = newData.width;
        to.height = newData.height;
    }
    else {
        to.width = newData[0].length;
        to.height = newData.length;
    }
    return to;
};
const createFramebuffer = (gl) => {
    const fb = gl.createFramebuffer(); // analog to createBuffer
    if (!fb) {
        throw new Error(`Error creating framebuffer`);
    }
    return fb;
};
/**
 * The operations `clear`, `drawArrays` and `drawElements` only affect the currently bound framebuffer.
 *
 * Note that binding the framebuffer does *not* mean binding its texture.
 * In fact, if there is a bound texture, it must be the *input* to a shader, not the output.
 * Therefore, a framebuffer's texture must not be bound when the framebuffer is.
 */
const bindFramebuffer = (gl, fbo, manualViewport) => {
    gl.bindFramebuffer(gl.FRAMEBUFFER, fbo.framebuffer);
    // It's EXTREMELY IMPORTANT to remember to call gl.viewport and set it to the size of the thing your rendering to.
    // https://webglfundamentals.org/webgl/lessons/webgl-render-to-texture.html
    if (manualViewport) {
        if ((fbo.width / fbo.height) !== (manualViewport[2] / manualViewport[3])) {
            console.warn(`Your viewport-aspect is different from the framebuffer-aspect.`);
        }
        gl.viewport(...manualViewport);
    }
    else {
        gl.viewport(0, 0, fbo.width, fbo.height);
    }
};
/**
 * Webgl renders to the viewport, which is relative to canvas.width * canvas.height.
 * (To be more precise, only *polygons* are clipped to the viewport.
 * Operations like `clearColor()` et.al., will still draw to the *full* canvas.width * height!
 * If you want to also constrain clearColor, use `scissor` instead of viewport.)
 * That canvas.width * canvas.height then gets stretched to canvas.clientWidth * canvas.clientHeight.
 * (Note: the full canvas.width gets stretched to clientWidth, not just the viewport!)
 */
const bindOutputCanvasToFramebuffer = (gl, manualViewport) => {
    gl.bindFramebuffer(gl.FRAMEBUFFER, null);
    // It's EXTREMELY IMPORTANT to remember to call gl.viewport and set it to the size of the thing your rendering to.
    // https://webglfundamentals.org/webgl/lessons/webgl-render-to-texture.html
    if (manualViewport) {
        if ((gl.canvas.width / gl.canvas.height) !== (manualViewport[2] / manualViewport[3])) {
            console.warn(`Your viewport-aspect is different from the canvas-aspect.`);
        }
        gl.viewport(...manualViewport);
    }
    else {
        // Note: don't use clientWidth here.
        gl.viewport(0, 0, gl.canvas.width, gl.canvas.height);
    }
};
/**
 * A framebuffer can have a texture - that is the bitmap that the shader-*out*put is drawn on.
 * Shaders may also have one or more *in*put texture(s), which must be provided to the shader as a uniform sampler2D.
 * Only the shader needs to know about any potential input texture, the framebuffer will always only know about it's output texture.
 */
const bindTextureToFramebuffer = (gl, texture, fb) => {
    gl.bindFramebuffer(gl.FRAMEBUFFER, fb);
    gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture.texture, 0); // analog to bufferData
    if (gl.checkFramebufferStatus(gl.FRAMEBUFFER) !== gl.FRAMEBUFFER_COMPLETE) {
        throw new Error(`Error creating framebuffer: framebuffer-status: ${gl.checkFramebufferStatus(gl.FRAMEBUFFER)} ; error-code: ${gl.getError()}`);
    }
    gl.bindFramebuffer(gl.FRAMEBUFFER, null);
    const fbo = {
        framebuffer: fb,
        texture: texture,
        width: texture.width,
        height: texture.height
    };
    return fbo;
};
/**
 * Fetch uniform's location (uniform declared in some shader). Slow! Do *before* render loop.
 */
const getUniformLocation = (gl, program, uniformName) => {
    const loc = gl.getUniformLocation(program, uniformName);
    if (loc === null) {
        throw new Error(`Couldn't find uniform ${uniformName} in program.`);
    }
    return loc;
};
/**
 * Contrary to attributes, uniforms don't need to be stored in a buffer. (Note: in WebGL 2.0, however, there *are* uniform buffers!)
 *
 * 'v' is not about the shader, but how you provide data from the js-side.
 * uniform1fv(loc, [3.19]) === uniform1f(loc, 3.19)
 *
 * |js                                      |          shader                  |
 * |----------------------------------------|----------------------------------|
 * |uniform1f(loc, 3.19)                    |  uniform float u_pi;             |
 * |uniform2f(loc, 3.19, 2.72)              |  uniform vec2 u_constants;       |
 * |uniform2fv(loc, [3.19, 2.72])           |  uniform vec2 u_constants;       |
 * |uniform1fv(loc, [1, 2, 3, 4, 5, 6])     |  uniform float u_kernel[6];      |
 * |uniform2fv(loc, [1, 2, 3, 4, 5, 6])     |  uniform vec2 u_observations[3]; |
 * |uniformMatrix3fv(loc, [[...], [...]])   |  uniform mat3 u_matrix;          |
 *
 * A note about `structs`. A shader code like this:
 * ```glsl
 * struct LightInfo {
 *    vec4 Position;
 *    vec3 La;
 * };
 * uniform LightInfo Light;
 * ```
 * ... is accessed like that:
 * ```js
 * const lightPosLoc = gl.getUniformLocation(program, "Light.Position");
 * const lightLaLoc = gl.getUniformLocation(program, "Light.La");
 * gl.uniform4fv(lightPosLoc, [1, 2, 3, 4]);
 * gl.uniform3fv(lightLaLoc, [1, 2, 3]);
 * ```
 *
 */
const bindValueToUniform = (gl, uniformLocation, type, values) => {
    switch (type) {
        case 'bool':
            gl.uniform1i(uniformLocation, values[0]);
            break;
        case 'bvec2':
            gl.uniform2i(uniformLocation, values[0], values[1]);
            break;
        case 'bvec3':
            gl.uniform3i(uniformLocation, values[0], values[1], values[2]);
            break;
        case 'bvec4':
            gl.uniform4i(uniformLocation, values[0], values[1], values[2], values[3]);
            break;
        case 'bool[]':
            gl.uniform1iv(uniformLocation, values);
            break;
        case 'bvec2[]':
            gl.uniform2iv(uniformLocation, values);
            break;
        case 'bvec3[]':
            gl.uniform3iv(uniformLocation, values);
            break;
        case 'bvec4[]':
            gl.uniform4iv(uniformLocation, values);
            break;
        case 'int':
            gl.uniform1i(uniformLocation, values[0]);
            break;
        case 'ivec2':
            gl.uniform2i(uniformLocation, values[0], values[1]);
            break;
        case 'ivec3':
            gl.uniform3i(uniformLocation, values[0], values[1], values[2]);
            break;
        case 'ivec4':
            gl.uniform4i(uniformLocation, values[0], values[1], values[2], values[3]);
            break;
        case 'int[]':
            gl.uniform1iv(uniformLocation, values);
            break;
        case 'ivec2[]':
            gl.uniform2iv(uniformLocation, values);
            break;
        case 'ivec3[]':
            gl.uniform3iv(uniformLocation, values);
            break;
        case 'ivec4[]':
            gl.uniform4iv(uniformLocation, values);
            break;
        case 'float':
            gl.uniform1f(uniformLocation, values[0]);
            break;
        case 'vec2':
            gl.uniform2f(uniformLocation, values[0], values[1]);
            break;
        case 'vec3':
            gl.uniform3f(uniformLocation, values[0], values[1], values[2]);
            break;
        case 'vec4':
            gl.uniform4f(uniformLocation, values[0], values[1], values[2], values[3]);
            break;
        case 'float[]':
            gl.uniform1fv(uniformLocation, values);
            break;
        case 'vec2[]':
            gl.uniform2fv(uniformLocation, values);
            break;
        case 'vec3[]':
            gl.uniform3fv(uniformLocation, values);
            break;
        case 'vec4[]':
            gl.uniform4fv(uniformLocation, values);
            break;
        // In the following *matrix* calls, the 'transpose' parameter must always be false.
        // Quoting the OpenGL ES 2.0 spec:
        // If the transpose parameter to any of the UniformMatrix* commands is
        // not FALSE, an INVALID_VALUE error is generated, and no uniform values are
        // changed.
        case 'mat2':
            gl.uniformMatrix2fv(uniformLocation, false, values);
            break;
        case 'mat3':
            gl.uniformMatrix3fv(uniformLocation, false, values);
            break;
        case 'mat4':
            gl.uniformMatrix4fv(uniformLocation, false, values);
            break;
        default:
            throw Error(`Type ${type} not implemented.`);
    }
};
/**
 * (From https://hacks.mozilla.org/2013/04/the-concepts-of-webgl/ and https://stackoverflow.com/questions/56303648/webgl-rendering-buffers:)
 * Ignoring handmade framebuffers, WebGl has two framebuffers that are always in use: the `frontbuffer/displaybuffer` and the `backbuffer/drawingbuffer`.
 * WebGl per default renders to the `drawingbuffer`, aka. the `backbuffer`.
 * There is also the currently displayed buffer, named the `frontbuffer` aka. the `displaybuffer`.
 * the WebGL programmer has no explicit access to the frontbuffer whatsoever.
 *
 * Once you called `clear`, `drawElements` or `drawArrays`, the browser marks the canvas as `needs to be composited`.
 * Assuming `preserveDrawingBuffer == false` (the default): Immediately before compositing, the browser
 *  - swaps the back- and frontbuffer
 *  - clears the new backbuffer.
 * If `preserveDrawingBuffer === true`: Immediately before compositing, the browser
 *  - copies the drawingbuffer to the frontbuffer.
 *
 * As a consequence, if you're going to use canvas.toDataURL or canvas.toBlob or gl.readPixels or any other way of getting data from a WebGL canvas,
 * unless you read it in the same event then it will likely be clear when you try to read it.
 *
 * In the past, old games always preserved the drawing buffer, so they'd only have to change those pixels that have actually changed. Nowadays preserveDrawingBuffer is false by default.
 *
 * A (almost brutal) workaround to get the canvas to preserve the drawingBuffer can be found here: https://stackoverflow.com/questions/26783586/canvas-todataurl-returns-blank-image
 */
const getCurrentFramebuffersPixels = (canvas) => {
    const gl = canvas.getContext('webgl');
    if (!gl) {
        throw new Error('no context');
    }
    const format = gl.getParameter(gl.IMPLEMENTATION_COLOR_READ_FORMAT);
    const type = gl.getParameter(gl.IMPLEMENTATION_COLOR_READ_TYPE);
    let pixels;
    if (type === gl.UNSIGNED_BYTE) {
        pixels = new Uint8Array(gl.drawingBufferWidth * gl.drawingBufferHeight * 4);
    }
    else if (type === gl.UNSIGNED_SHORT_5_6_5 || type === gl.UNSIGNED_SHORT_4_4_4_4 || type === gl.UNSIGNED_SHORT_5_5_5_1) {
        pixels = new Uint16Array(gl.drawingBufferWidth * gl.drawingBufferHeight * 4);
    }
    else if (type === gl.FLOAT) {
        pixels = new Float32Array(gl.drawingBufferWidth * gl.drawingBufferHeight * 4);
    }
    else {
        throw new Error(`Did not understand pixel data type ${type} for format ${format}`);
    }
    // Just like `toDataURL` or `toBlob`, `readPixels` does not access the frontbuffer.
    // It accesses the backbuffer or any other currently active framebuffer.
    gl.readPixels(0, 0, canvas.width, canvas.height, format, type, pixels);
    return pixels;
};
const getDebugInfo = (gl) => {
    const baseInfo = {
        renderer: gl.getParameter(gl.RENDERER),
        currentProgram: gl.getParameter(gl.CURRENT_PROGRAM),
        arrayBuffer: gl.getParameter(gl.ARRAY_BUFFER_BINDING),
        elementArrayBuffer: gl.getParameter(gl.ELEMENT_ARRAY_BUFFER_BINDING),
        frameBuffer: gl.getParameter(gl.FRAMEBUFFER_BINDING),
        renderBuffer: gl.getParameter(gl.RENDERBUFFER_BINDING),
        texture: gl.getParameter(gl.TEXTURE_BINDING_2D),
        viewPort: gl.getParameter(gl.VIEWPORT)
    };
    const programInfo = {
        infoLog: gl.getProgramInfoLog(baseInfo.currentProgram)
    };
    return {
        baseInfo, programInfo
    };
};

// dead-simple hash function - not intended to be secure in any way.
const hash = function (s) {
    let h = 0;
    for (const c of s) {
        h += c.charCodeAt(0);
    }
    return `${h}`;
};
class Program {
    constructor(gl, vertexShaderSource, fragmentShaderSource) {
        this.vertexShaderSource = vertexShaderSource;
        this.fragmentShaderSource = fragmentShaderSource;
        this.program = createShaderProgram(gl, vertexShaderSource, fragmentShaderSource);
        this.id = hash(vertexShaderSource + fragmentShaderSource);
    }
}
class Uniform {
    constructor(gl, program, variableName, type, data) {
        this.location = getUniformLocation(gl, program.program, variableName);
        this.type = type;
        this.value = data;
        this.variableName = variableName;
    }
}
class Texture {
    constructor(gl, program, variableName, im, bindPoint) {
        this.location = getUniformLocation(gl, program.program, variableName);
        if (im instanceof HTMLImageElement || im instanceof HTMLCanvasElement) {
            this.texture = createTexture(gl, im);
        }
        else {
            this.texture = im;
        }
        this.bindPoint = bindPoint;
        this.variableName = variableName;
    }
}
class DataTexture {
    constructor(gl, program, variableName, data, bindPoint) {
        this.location = getUniformLocation(gl, program.program, variableName);
        this.texture = createDataTexture(gl, data);
        this.bindPoint = bindPoint;
        this.variableName = variableName;
    }
}
class Attribute {
    constructor(gl, program, variableName, data, drawingMode = 'triangles') {
        let glDrawingMode;
        switch (drawingMode) {
            case 'triangles':
                glDrawingMode = gl.TRIANGLES;
                break;
            case 'lines':
                glDrawingMode = gl.LINES;
                break;
            case 'points':
                glDrawingMode = gl.POINTS;
                break;
            default:
                throw new Error(`Invalid drawing mode ${drawingMode}`);
        }
        this.location = getAttributeLocation(gl, program.program, variableName);
        this.value = createFloatBuffer(gl, data, glDrawingMode);
        this.variableName = variableName;
        this.drawingMode = glDrawingMode;
    }
}
class Index {
    constructor(gl, indices, drawingMode = 'triangles') {
        let glDrawingMode;
        switch (drawingMode) {
            case 'triangles':
                glDrawingMode = gl.TRIANGLES;
                break;
            case 'lines':
                glDrawingMode = gl.LINES;
                break;
            case 'points':
                glDrawingMode = gl.POINTS;
                break;
            default:
                throw new Error(`Invalid drawing mode ${drawingMode}`);
        }
        this.index = createIndexBuffer(gl, indices, glDrawingMode);
    }
}
function first(arr, condition) {
    for (const el of arr) {
        if (condition(el)) {
            return el;
        }
    }
    return null;
}
function parseProgram(program) {
    const attributeRegex = /^\s*attribute (int|float|vec2|vec3|vec4|mat2|mat3|mat4) (\w*);/gm;
    const uniformRegex = /^\s*uniform (int|float|vec2|vec3|vec4|mat2|mat3|mat4) (\w*)(\[\d\])*;/gm;
    const textureRegex = /^\s*uniform sampler2D (\w*);/gm;
    const precisionRegex = /^\s*precision (\w*) float;/gm;
    const shaderCode = program.fragmentShaderSource + '\n\n\n' + program.vertexShaderSource;
    const attributeNames = [];
    let attributeMatches;
    while ((attributeMatches = attributeRegex.exec(shaderCode)) !== null) {
        attributeNames.push(attributeMatches[2]);
    }
    const uniformNames = [];
    let uniformMatches;
    while ((uniformMatches = uniformRegex.exec(shaderCode)) !== null) {
        uniformNames.push(uniformMatches[2]);
    }
    const textureNames = [];
    let textureMatches;
    while ((textureMatches = textureRegex.exec(shaderCode)) !== null) {
        textureNames.push(textureMatches[1]);
    }
    const precisions = [];
    let precisionMatches;
    while ((precisionMatches = precisionRegex.exec(shaderCode)) !== null) {
        precisions.push(precisionMatches[1]);
    }
    return [attributeNames, uniformNames, textureNames, precisions];
}
class Shader {
    constructor(program, attributes, uniforms, textures, index) {
        this.program = program;
        this.attributes = attributes;
        this.uniforms = uniforms;
        this.textures = textures;
        this.index = index;
        const [attributeNames, uniformNames, textureNames, precisions] = parseProgram(program);
        for (const attrName of attributeNames) {
            const found = attributes.filter(a => a.variableName === attrName);
            if (found.length !== 1) {
                throw new Error(`Provided ${found.length} values for shader's attribute ${attrName}.`);
            }
        }
        for (const uniformName of uniformNames) {
            const found = uniforms.filter(a => a.variableName === uniformName);
            if (found.length !== 1) {
                throw new Error(`Provided ${found.length} values for shader's uniform ${uniformName}.`);
            }
        }
        for (const texName of textureNames) {
            const found = textures.filter(a => a.variableName === texName);
            if (found.length !== 1) {
                throw new Error(`Provided ${found.length} values for shader's texture ${texName}.`);
            }
        }
        if (precisions.length === 1) {
            console.warn(`You have only provided one precision qualifier.
            This can cause issues when you want to use a uniform in both the vertex- and the fragment-shader.`);
        }
        const lengths = this.attributes.map(a => a.value.vectorCount);
        if (Math.min(...lengths) !== Math.max(...lengths)) {
            throw new Error(`Your attributes are not of the same length!`);
        }
    }
    bind(gl) {
        bindProgram(gl, this.program.program);
        for (const a of this.attributes) {
            bindBufferToAttribute(gl, a.location, a.value);
        }
        for (const u of this.uniforms) {
            bindValueToUniform(gl, u.location, u.type, u.value);
        }
        for (const t of this.textures) {
            bindTextureToUniform(gl, t.texture.texture, t.bindPoint, t.location);
        }
        if (this.index) {
            bindIndexBuffer(gl, this.index.index);
        }
    }
    render(gl, background, frameBuffer, viewport) {
        if (!frameBuffer) {
            bindOutputCanvasToFramebuffer(gl, viewport);
        }
        else {
            bindFramebuffer(gl, frameBuffer, viewport);
        }
        if (background) {
            clearBackground(gl, background);
        }
        if (this.index) {
            drawElements(gl, this.index.index);
        }
        else {
            const firstAttribute = this.attributes[0];
            drawArray(gl, firstAttribute.value);
        }
    }
    updateAttributeData(gl, variableName, newData) {
        const attribute = first(this.attributes, el => el.variableName === variableName);
        if (!attribute) {
            throw new Error(`No such attribute ${variableName} to be updated.`);
        }
        updateBufferData(gl, attribute.value, newData);
    }
    updateUniformData(gl, variableName, newData) {
        const uniform = first(this.uniforms, el => el.variableName === variableName);
        if (!uniform) {
            throw new Error(`No such uniform ${variableName} to be updated.`);
        }
        uniform.value = newData;
    }
    updateTextureData(gl, variableName, newImage) {
        const original = first(this.textures, t => t.variableName === variableName);
        if (!original) {
            throw new Error(`No such texture ${variableName} to be updated.`);
        }
        const newTextureObject = updateTexture(gl, original.texture, newImage);
        original.texture = newTextureObject;
    }
}
class Framebuffer {
    constructor(gl, width, height) {
        const fb = createFramebuffer(gl);
        const fbTexture = createEmptyTexture(gl, width, height);
        const fbo = bindTextureToFramebuffer(gl, fbTexture, fb);
        this.fbo = fbo;
    }
}
function renderLoop(fps, renderFunction) {
    const tDeltaTarget = 1000 * 1.0 / fps;
    let tDelta = tDeltaTarget;
    let tStart, tNow, tSleep;
    const render = () => {
        tStart = window.performance.now();
        renderFunction(tDelta);
        tNow = window.performance.now();
        tDelta = tNow - tStart;
        tSleep = Math.max(tDeltaTarget - tDelta, 0);
        setTimeout(() => {
            requestAnimationFrame(render);
        }, tSleep);
    };
    render();
}
class Entity {
    constructor(program, attributes, uniforms, textures, updateFunction) {
        this.program = program;
        this.attributes = attributes;
        this.uniforms = uniforms;
        this.textures = textures;
        this.updateFunction = updateFunction;
    }
    update(tDelta) {
        this.updateFunction(tDelta, this.attributes, this.uniforms);
    }
}
class Engine {
    constructor() {
        this.entities = [];
    }
    renderLoop(gl, fps) {
        setup3dScene(gl);
        const tDeltaTarget = 1000 * 1.0 / fps;
        let tStart, tNow, tDelta, tSleep;
        let currentShader = '';
        const render = () => {
            tStart = window.performance.now();
            // Part 1: allow objects to update their state
            for (const e of this.entities) {
                e.update(tDeltaTarget);
            }
            // Part 2: do the actual rendering work here
            clearBackground(gl, [.7, .7, .7, 1]);
            for (const e of this.entities) {
                if (e.program.id !== currentShader) {
                    bindProgram(gl, e.program.program);
                    currentShader = e.program.id;
                }
                for (const a of e.attributes) {
                    bindBufferToAttribute(gl, a.location, a.value);
                }
                for (const u of e.uniforms) {
                    bindValueToUniform(gl, u.location, u.type, u.value);
                }
                for (const t of e.textures) {
                    bindTextureToUniform(gl, t.texture.texture, t.bindPoint, t.location);
                }
                gl.drawArrays(gl.TRIANGLES, 0, e.attributes[0].value.vectorCount);
            }
            // Part 3: time-management
            tNow = window.performance.now();
            tDelta = tNow - tStart;
            tSleep = Math.max(tDeltaTarget - tDelta, 0);
            setTimeout(() => {
                requestAnimationFrame(render);
            }, tSleep);
        };
        render();
    }
    addEntity(entity) {
        this.entities.push(entity);
        this.sortEntities();
    }
    sortEntities() {
        this.entities.sort((a, b) => {
            return (a.program.id > b.program.id) ? 1 : -1;
        });
    }
}

/**
 * While webgl's clip space has coordinates [-1, 1] (left to right), [-1, 1] (bottom to top),
 * textures go from [0, 1] (left to right), [0, 1] (bottom to top).
 */
const triangleA = (width, height) => {
    return {
        vertices: [
            [-width / 2, -height / 2, 0],
            [0, height / 2, 0],
            [width / 2, -height / 2, 0]
        ],
        texturePositions: [
            [0, 0],
            [0, 1],
            [1, 0]
        ]
    };
};
const triangleE = (width, height) => {
    return {
        vertices: [
            [-width / 2, -height / 2, 0],
            [0, height / 2, 0],
            [width / 2, -height / 2, 0]
        ],
        texturePositions: [
            [0, 0],
            [0, 1],
            [1, 0]
        ],
        vertexIndices: [
            [0, 1, 2]
        ]
    };
};
const rectangleA = (width, height) => {
    return {
        vertices: [
            [-width / 2, height / 2, 0],
            [-width / 2, -height / 2, 0],
            [width / 2, -height / 2, 0],
            [-width / 2, height / 2, 0],
            [width / 2, -height / 2, 0],
            [width / 2, height / 2, 0],
        ],
        texturePositions: [
            [0, 1],
            [0, 0],
            [1, 0],
            [0, 1],
            [1, 0],
            [1, 1]
        ]
    };
};
const rectangleE = (width, height) => {
    return {
        vertices: [
            [-width / 2, height / 2, 0],
            [-width / 2, -height / 2, 0],
            [width / 2, -height / 2, 0],
            [width / 2, height / 2, 0],
        ],
        texturePositions: [
            [0, 1],
            [0, 0],
            [1, 0],
            [1, 1]
        ],
        vertexIndices: [
            [0, 1, 2],
            [0, 2, 3]
        ]
    };
};

const displayImageOn = (canvas, image) => {
    const gl = canvas.getContext('webgl');
    if (!gl) {
        throw new Error('No context');
    }
    const vertexShaderSource = `
    attribute vec4 a_vertex;
    attribute vec2 a_textureCoord;
    varying vec2 v_textureCoord;
    void main() {
        v_textureCoord = a_textureCoord;
        gl_Position = a_vertex;
    }
    `;
    const fragmentShaderSource = `
    precision mediump float;
    uniform sampler2D u_texture;
    // uniform vec2 u_textureSize;
    varying vec2 v_textureCoord;
    void main() {
        // vec2 delta = vec2(1., 1.) / u_textureSize;
        gl_FragColor = texture2D(u_texture, v_textureCoord); //  * 0. + vec4(5., 5., 0., 1.);
    }
    `;
    const program = createShaderProgram(gl, vertexShaderSource, fragmentShaderSource);
    bindProgram(gl, program);
    const rct = rectangleA(1.3, 1.3);
    const bxData = createFloatBuffer(gl, rct.vertices);
    const bxLoc = getAttributeLocation(gl, program, 'a_vertex');
    bindBufferToAttribute(gl, bxLoc, bxData);
    const texCoords = createFloatBuffer(gl, rct.texturePositions);
    const texCoordsLoc = getAttributeLocation(gl, program, 'a_textureCoord');
    bindBufferToAttribute(gl, texCoordsLoc, texCoords);
    const texture = createTexture(gl, image);
    const textureLoc = getUniformLocation(gl, program, 'u_texture');
    bindTextureToUniform(gl, texture.texture, 0, textureLoc);
    clearBackground(gl, [.9, .9, .9, 1.0]);
    gl.drawArrays(gl.TRIANGLES, 0, rct.vertices.length);
};
const createTextCanvas = (text, width = 256, height = 256, color = 'red') => {
    const ctx = document.createElement('canvas').getContext('2d');
    if (!ctx) {
        throw new Error('no context');
    }
    ctx.canvas.width = width;
    ctx.canvas.height = height;
    ctx.font = `bold ${height * 5 / 6 | 0}px sans-serif`;
    ctx.textAlign = 'center';
    ctx.textBaseline = 'middle';
    ctx.fillStyle = color;
    ctx.fillText(text, width / 2, height / 2);
    return ctx.canvas;
};
const canvasToImage = (canvas) => {
    const image = document.createElement('img');
    image.width = canvas.width;
    image.height = canvas.height;
    image.src = canvas.toDataURL('image/png');
    return image;
};
const arrayToCanvas = (data) => {
    const rows = data.length;
    const cols = data[0].length;
    const buffer = new Uint8ClampedArray(cols * rows * 4);
    for (let r = 0; r < rows; r++) {
        for (let c = 0; c < cols; c++) {
            const pos = (r * cols + c) * 4;
            buffer[pos] = data[r][c][0];
            buffer[pos + 1] = data[r][c][1];
            buffer[pos + 2] = data[r][c][2];
            buffer[pos + 3] = data[r][c][3];
        }
    }
    const canvas = document.createElement('canvas');
    const ctx = canvas.getContext('2d');
    canvas.width = cols;
    canvas.height = rows;
    const imageDataContainer = ctx.createImageData(cols, rows);
    imageDataContainer.data.set(buffer);
    ctx.putImageData(imageDataContainer, 0, 0);
    return canvas;
};

class DtmLayer extends ImageLayer {
    constructor(options) {
        super(options);
    }
    createRenderer() {
        this.renderer = new DtmImageRenderer(this);
        return this.renderer;
    }
    updateSunAngle(angle) {
        this.renderer.updateSunAngle(angle);
    }
}
/**
 * This renderer serves as a illustration of a very common technique in WebGL: normal-maps.
 * Here we use a texture from NASA's SRTM mission as our base-DTM.
 * Based on this, we calculate surface-normals. For each pixel in the DTM, we check how the surface-normal
 * is aligned with an incoming sun-ray.
 *
 * In real-world applications, many more such techniques are employed. Alongside normal-maps there are:
 *  - specular maps,
 *  - occlusion maps,
 *  - ...
 */
class DtmImageRenderer extends LayerRenderer {
    constructor(layer) {
        super(layer);
        this.state = 'loading';
        // Step 1: setting up canvas
        const canvas = document.createElement('canvas');
        canvas.width = 1200;
        canvas.height = 800;
        canvas.style.position = 'absolute';
        // Step 2: setting up webgl
        const gl = canvas.getContext('webgl');
        // Step 3: setting up variables for program
        const source = layer.getSource();
        const currentProjection = source.getProjection();
        const bbox = source.getImageExtent();
        const rectangleInWorldPosition = this.bboxOntoRectangle(2, 2, bbox);
        const image = createTextCanvas('test', 2048, 2048, 'red');
        // Step 4: setting up program
        const program = new Program(gl, `
            attribute vec3 a_position;
            attribute vec2 a_texturePosition;
            uniform mat3 u_world2pix;
            uniform mat3 u_pix2canv;
            varying vec2 v_texturePosition;
            void main() {
                vec3 pixelPosition = u_world2pix * vec3(a_position.x, a_position.y, 1.);
                vec3 canvasPosition = u_pix2canv * pixelPosition;
                gl_Position = vec4(canvasPosition.x, canvasPosition.y, 0., 1.);
                v_texturePosition = a_texturePosition;
            }
        `, `
            precision mediump float;
            uniform sampler2D u_srtm;
            uniform float u_imageSize;
            uniform vec3 u_sun;
            varying vec2 v_texturePosition;
            void main() {
                float delta = 4. / u_imageSize;
                float top = texture2D(u_srtm, vec2(v_texturePosition.x,         1. - v_texturePosition.y + delta)).r;
                float bot = texture2D(u_srtm, vec2(v_texturePosition.x,         1. - v_texturePosition.y - delta)).r;
                float lft = texture2D(u_srtm, vec2(v_texturePosition.x + delta, 1. - v_texturePosition.y        )).r;
                float rgt = texture2D(u_srtm, vec2(v_texturePosition.x - delta, 1. - v_texturePosition.y        )).r;

                vec3 surfaceNormal = vec3(
                    lft - rgt,
                    bot - top,
                    2. * delta
                );
                surfaceNormal = normalize(surfaceNormal);
                vec3 sunNormal = normalize(u_sun);
                float alignment = abs(dot(sunNormal, surfaceNormal));

                gl_FragColor = vec4(0., 0., 0., 0.5 * alignment);
            }
        `);
        bindProgram(gl, program.program); // todo: is this required?
        const shader = new Shader(program, [
            new Attribute(gl, program, 'a_position', rectangleInWorldPosition.vertices),
            new Attribute(gl, program, 'a_texturePosition', rectangleInWorldPosition.texturePositions)
        ], [
            new Uniform(gl, program, 'u_imageSize', 'float', [2048.]),
            new Uniform(gl, program, 'u_sun', 'vec3', [0., 0., 1.]),
            new Uniform(gl, program, 'u_world2pix', 'mat3', flattenRecursive([
                [1., 0., 0.],
                [0., 1., 0.],
                [0., 0., 1.]
            ])),
            new Uniform(gl, program, 'u_pix2canv', 'mat3', flattenRecursive([
                [1. / (canvas.width / 2), 0., 0.],
                [0, -1. / (canvas.height / 2), 0.],
                [-1., 1., 1.]
            ]))
        ], [
            new Texture(gl, program, 'u_srtm', image, 0)
        ]);
        shader.bind(gl);
        // binding data for later use
        this.shader = shader;
        this.canvas = canvas;
        this.gl = gl;
        this.projection = currentProjection;
        // step 5: loading actual image
        const imageWrapper = source.getImage(bbox, 0.02197265625, 2.440000295639038, currentProjection);
        imageWrapper.addEventListener('change', (evt) => {
            const newImage = imageWrapper.getImage();
            this.shader.updateTextureData(this.gl, 'u_srtm', newImage);
            this.shader.bind(this.gl);
            this.state = 'ready';
            super.getLayer().changed();
        });
        imageWrapper.load();
    }
    prepareFrame(frameState) {
        if (this.state === 'ready') {
            const c2pT = frameState.coordinateToPixelTransform;
            const worldToPixelTransform = [
                [c2pT[0], c2pT[1], 0.],
                [c2pT[2], c2pT[3], 0.],
                [c2pT[4], c2pT[5], 1.]
            ];
            this.shader.updateUniformData(this.gl, 'u_world2pix', flattenRecursive(worldToPixelTransform));
            this.shader.bind(this.gl); // <--- @TODO: inefficient! Only re-bind world2pix matrix.
            if (frameState.viewState.projection !== this.projection) {
                this.reprojectImage(frameState.viewState.projection);
            }
        }
        return true;
    }
    renderFrame(frameState, target) {
        if (this.state === 'ready') {
            this.shader.render(this.gl);
            this.transformCanvas(frameState);
        }
        return this.canvas;
    }
    renderDeclutter(frameState) {
    }
    updateSunAngle(angle) {
        this.shader.updateUniformData(this.gl, 'u_sun', [angle[0], angle[1], 1.0]);
        this.shader.bind(this.gl);
        this.shader.render(this.gl);
    }
    bboxOntoRectangle(width, height, bbox) {
        const rect = rectangleA(width, height);
        for (const vertex of rect.vertices) {
            const x = vertex[0];
            const y = vertex[1];
            vertex[0] = (x === width / 2) ? bbox[2] : bbox[0];
            vertex[1] = (y === height / 2) ? bbox[3] : bbox[1];
        }
        return rect;
    }
    reprojectImage(targetProjection) {
        const source = super.getLayer().getSource();
        const sourceProjection = source.getProjection();
        const bbox = source.getImageExtent();
        const bboxInTargetProj = transformExtent(bbox, sourceProjection, targetProjection);
        const newRectangleInWorldPosition = this.bboxOntoRectangle(2, 2, bboxInTargetProj);
        this.shader.updateAttributeData(this.gl, 'a_position', newRectangleInWorldPosition.vertices);
        this.shader.bind(this.gl);
    }
    transformCanvas(frameState) {
        const layerState = frameState.layerStatesArray[frameState.layerIndex];
        const pixelRatio = frameState.pixelRatio;
        const size = frameState.size;
        const width = Math.round(size[0] * pixelRatio);
        const height = Math.round(size[1] * pixelRatio);
        const opacity = layerState.opacity;
        this.canvas.width = width;
        this.canvas.height = height;
        this.canvas.style.opacity = `${opacity}`;
        const pix2canv = [
            [1. / (this.canvas.width / 2), 0., 0.],
            [0, -1. / (this.canvas.height / 2), 0.],
            [-1., 1., 1.]
        ];
        this.shader.updateUniformData(this.gl, 'u_pix2canv', flattenRecursive(pix2canv));
        // this.interpolationShader.bind(this.gl); <-- not required: already happens in `prepareFrame`
    }
}

class InterpolationLayer extends VectorLayer {
    constructor(options) {
        super(options);
        this.options = options;
    }
    createRenderer() {
        return new InterpolationRenderer(this, this.options.renderSettings);
    }
    updateParas(power, smooth, showLabels) {
        const newSettings = {
            colorRamp: this.options.renderSettings.colorRamp,
            maxEdgeLength: this.options.renderSettings.maxEdgeLength,
            storeInterpolatedPixelData: this.options.renderSettings.storeInterpolatedPixelData,
            valueProperty: this.options.renderSettings.valueProperty,
            power: power,
            showLabels: showLabels,
            smooth: smooth,
        };
        super.getRenderer().updateSettings(newSettings);
        this.options.renderSettings = newSettings;
    }
}
/**
 * This renderer runs three shaders in a row.
 *  1. interpolationShader: takes every observation at every pixel and executes the interpolation. The values are stored in `valueFb`.
 *  2. colorizationShader: uses the interpolated values from valueFb to apply the colorization according to the given colorRamp and smoothing-options.
 *  3. arrangementShader: the previous shaders have moved the data in the center of the canvas. this shader now arranges the pixels to the correct position relative to the map.
 *
 * Only the third shader needs to be executed with every frame. This way, the operation-heavy interpolation does not slow down the map.
 * It generally makes sense to arrange shaders in such a way that all openlayers-perspective-operations occur in the last shader.
 *
 * valueFb is also being used to handle click events: from this structure we get the actual value at a pixel when the user clicks.
 *
 * Note a few caveats.
 * This implementation is not really intended for updating observations, maxEdgeLength or colorRamps at runtime. These parameters are rather intended for the developer to set once.
 * While you can change the color-ramp at runtime, it's length is hardcoded in the colorization shader, so you'd have to recompile it to properly reflect the new ramp.
 * In the same way, the interpolation-shader has the number of observations baked into it. When new data becomes available, you must recompile the interpolation shader.
 */
class InterpolationRenderer extends LayerRenderer {
    constructor(layer, settings) {
        super(layer);
        this.settings = settings;
        // setting up HTML element
        this.container = document.createElement('div');
        this.container.classList.add('ol-layer');
        this.container.style.setProperty('position', 'absolute');
        this.container.style.setProperty('width', '100%');
        this.container.style.setProperty('height', '100%');
        this.webGlCanvas = document.createElement('canvas');
        this.webGlCanvas.style.setProperty('position', 'absolute');
        this.webGlCanvas.style.setProperty('left', '0px');
        this.webGlCanvas.style.setProperty('top', '0px');
        this.webGlCanvas.style.setProperty('width', '100%');
        this.webGlCanvas.style.setProperty('height', '100%');
        this.webGlCanvas.width = 1000; // <-- make smaller for better performance
        this.webGlCanvas.height = 1000; // <-- make smaller for better performance
        this.gl = this.webGlCanvas.getContext('webgl');
        this.container.appendChild(this.webGlCanvas);
        // setting up point-renderer
        this.pointRenderer = new CanvasVectorLayerRenderer(layer);
        // preparing data
        const source = layer.getSource();
        this.projection = source.getProjection();
        const { coords, values, bboxDelta, maxVal } = this.parseData(source, this.settings.valueProperty, this.settings.maxEdgeLength);
        const { observationsBbox, maxEdgeLengthBbox } = this.parseDataBbox(bboxDelta, coords, values, maxVal, this.settings.maxEdgeLength);
        this.bbox = bboxDelta;
        // setting up shaders
        const identity = [[1, 0, 0], [0, 1, 0], [0, 0, 1]];
        this.interpolationShader = createInverseDistanceInterpolationShader(this.gl, observationsBbox, maxVal, this.settings.power, maxEdgeLengthBbox);
        this.valueFb = new Framebuffer(this.gl, this.webGlCanvas.width, this.webGlCanvas.height);
        this.colorizationShader = createColorizationShader(this.gl, this.settings.colorRamp, maxVal, this.settings.smooth, this.valueFb);
        this.colorFb = new Framebuffer(this.gl, this.webGlCanvas.width, this.webGlCanvas.height);
        this.arrangementShader = createArrangementShader(this.gl, identity, identity, bboxDelta, this.colorFb);
        // running first two shaders once
        this.runInterpolationShader(this.valueFb.fbo);
        this.runColorizationShader(this.colorFb.fbo);
    }
    prepareFrame(frameState) {
        const layerState = frameState.layerStatesArray[frameState.layerIndex];
        this.webGlCanvas.style.opacity = `${layerState.opacity}`;
        if (frameState.viewState.projection !== this.projection) {
            this.projection = frameState.viewState.projection;
            const source = super.getLayer().getSource();
            const { coords, values, bboxDelta, maxVal } = this.parseData(source, this.settings.valueProperty, this.settings.maxEdgeLength);
            const { observationsBbox, maxEdgeLengthBbox } = this.parseDataBbox(bboxDelta, coords, values, maxVal, this.settings.maxEdgeLength);
            this.updateInterpolationShader(this.settings.power, observationsBbox, maxEdgeLengthBbox);
            this.runInterpolationShader(this.valueFb.fbo);
            this.runColorizationShader(this.colorFb.fbo);
            this.bbox = bboxDelta;
        }
        const c2pT = frameState.coordinateToPixelTransform;
        // using frameState.size instead of this.webGlCanvas.clientWidth because the latter is null when layer invisible.
        this.updateArrangementShader(c2pT, frameState.size[0], frameState.size[1], this.bbox);
        this.pointRenderer.prepareFrame(frameState);
        return true;
    }
    renderFrame(frameState, target) {
        this.runArrangementShader(); // @todo: arrangement shader could be replaced with a simple css-transformation-matrix.
        if (this.settings.showLabels) {
            const pointCanvas = this.pointRenderer.renderFrame(frameState, this.container);
            replaceChildren(this.container, [this.webGlCanvas, pointCanvas]);
        }
        else {
            replaceChildren(this.container, [this.webGlCanvas]);
        }
        return this.container;
    }
    renderDeclutter(frameState) {
    }
    updateSettings(newSettings) {
        const oldSettings = this.settings;
        this.settings = newSettings;
        if (newSettings.power !== oldSettings.power) {
            this.updateInterpolationShader(newSettings.power);
            this.runInterpolationShader(this.valueFb.fbo);
            this.updateColorizationShader(newSettings.smooth);
            this.runColorizationShader(this.colorFb.fbo);
        }
        else if (newSettings.smooth !== oldSettings.smooth) {
            this.updateColorizationShader(newSettings.smooth);
            this.runColorizationShader(this.colorFb.fbo);
        }
        super.getLayer().changed();
    }
    /**
     * Called at every renderFrame. Fast.
     */
    updateArrangementShader(coordinateToPixelTransform, canvasWidth, canvasHeight, bbox) {
        const world2pix = [
            [coordinateToPixelTransform[0], coordinateToPixelTransform[1], 0.],
            [coordinateToPixelTransform[2], coordinateToPixelTransform[3], 0.],
            [coordinateToPixelTransform[4], coordinateToPixelTransform[5], 1.]
        ];
        const pix2clip = [
            [1. / (canvasWidth / 2), 0., 0.],
            [0, -1. / (canvasHeight / 2), 0.],
            [-1., 1., 1.]
        ];
        this.arrangementShader.updateUniformData(this.gl, 'u_world2pix', flattenRecursive(world2pix));
        this.arrangementShader.updateUniformData(this.gl, 'u_pix2clip', flattenRecursive(pix2clip));
        this.arrangementShader.updateUniformData(this.gl, 'u_bbox', bbox);
    }
    /**
     * Called at every renderFrame. Fast.
     */
    runArrangementShader(target) {
        this.arrangementShader.bind(this.gl);
        this.arrangementShader.render(this.gl, [0, 0, 0, 0], target);
    }
    /**
     * Slow! Avoid calling this too often.
     */
    updateInterpolationShader(power, observations, maxEdgeLengthBbox) {
        this.interpolationShader.updateUniformData(this.gl, 'u_power', [power]);
        if (observations) {
            this.interpolationShader.updateTextureData(this.gl, 'u_dataTexture', [observations]);
        }
        if (maxEdgeLengthBbox) {
            this.interpolationShader.updateUniformData(this.gl, 'u_maxDistance', [maxEdgeLengthBbox]);
        }
    }
    /**
     * Slow! Avoid calling this too often.
     */
    runInterpolationShader(target) {
        this.interpolationShader.bind(this.gl);
        this.interpolationShader.render(this.gl, [0, 0, 0, 0], target);
        if (this.settings.storeInterpolatedPixelData) {
            this.interpolatedValues = getCurrentFramebuffersPixels(this.webGlCanvas);
        }
    }
    /**
     * Slow! Avoid calling this too often.
     */
    updateColorizationShader(smooth) {
        // this.colorizationShader.updateUniformData(this.gl, 'u_colorRampValues', colorRamp.map(e => e.val));
        // this.colorizationShader.updateUniformData(this.gl, 'u_colorRampColors', flattenRecursive( colorRamp.map(e => e.rgb) ));
        this.colorizationShader.updateUniformData(this.gl, 'u_smooth', [smooth ? 1 : 0]);
    }
    /**
     * Slow! Avoid calling this too often.
     */
    runColorizationShader(target) {
        this.colorizationShader.bind(this.gl);
        this.colorizationShader.render(this.gl, [0, 0, 0, 0], target);
    }
    parseData(source, valueProperty, maxEdgeLength) {
        let features = source.getFeatures();
        if (source instanceof Cluster) {
            features = source.getSource().getFeatures();
        }
        else {
            features = source.getFeatures();
        }
        const coords = features.map(f => f.getGeometry().getCoordinates());
        const values = features.map(f => parseFloat(f.getProperties()[valueProperty]));
        const bbox = getBbox(coords);
        const deltaX = bbox[2] - bbox[0];
        const deltaY = bbox[3] - bbox[1];
        let addX, addY;
        if (deltaX > deltaY) {
            addY = deltaX - deltaY;
            addX = 0;
        }
        else {
            addY = 0;
            addX = deltaY - deltaX;
        }
        const bboxDelta = [
            bbox[0] - maxEdgeLength,
            bbox[1] - maxEdgeLength,
            bbox[2] + addX + maxEdgeLength,
            bbox[3] + addY + maxEdgeLength
        ];
        const maxVal = values.reduce((prev, curr) => curr > prev ? curr : prev, 0);
        return {
            coords, values, bboxDelta, maxVal
        };
    }
    parseDataBbox(bbox, coords, values, maxVal, maxEdgeLength) {
        const observationsBbox = zip(coords, values).map(o => {
            const coordsBbox = worldCoords2clipBbox([o[0], o[1]], bbox);
            return [
                255 * (coordsBbox[0] + 1) / 2,
                255 * (coordsBbox[1] + 1) / 2,
                255 * o[2] / maxVal,
                255
            ];
        });
        const nrObservations = observationsBbox.length;
        const nextPowerOfTwo = nextPowerOf(nrObservations, 2);
        for (let i = 0; i < nextPowerOfTwo - nrObservations; i++) {
            observationsBbox.push([0, 0, 0, 0]);
        }
        const deltaX = bbox[2] - bbox[0];
        const deltaY = bbox[3] - bbox[1];
        const maxEdgeLengthBbox = maxEdgeLength / Math.max(deltaX, deltaY);
        return { observationsBbox, maxEdgeLengthBbox };
    }
}
const worldCoords2clipBbox = (point, bbox) => {
    const xPerct = (point[0] - bbox[0]) / (bbox[2] - bbox[0]);
    const yPerct = (point[1] - bbox[1]) / (bbox[3] - bbox[1]);
    const xClip = 2 * xPerct - 1;
    const yClip = 2 * yPerct - 1;
    return [xClip, yClip];
};
const createInverseDistanceInterpolationShader = (gl, observationsBbox, maxValue, power, maxEdgeLengthBbox) => {
    const maxObservations = 10000;
    const inverseDistanceProgram = new Program(gl, `
            precision mediump float;
            attribute vec3 a_position;
            attribute vec2 a_texturePosition;
            varying vec2 v_position;
            varying vec2 v_texturePosition;

            void main() {
                v_position = a_position.xy;
                v_texturePosition = a_texturePosition;
                gl_Position = vec4(a_position.xy, 0.0, 1.0);
            }
        `, `
            precision mediump float;
            uniform float u_power;
            uniform sampler2D u_dataTexture;
            uniform int u_nrDataPoints;
            uniform float u_maxValue;
            uniform float u_maxDistance;
            varying vec2 v_position;
            varying vec2 v_texturePosition;

            void main() {

                float valSum = 0.0;
                float wSum = 0.0;
                float minD = 10000.0;
                for (int i = 0; i < ${maxObservations}; i++) {
                    if (i > u_nrDataPoints) {
                        break;
                    }
                    vec4 dataPoint = texture2D(u_dataTexture, vec2(float(i) / float(u_nrDataPoints), 0.5));
                    if (dataPoint.w > 0.0) {  // texture is padded to next power of two with transparent 0-values.
                        vec2 coords = dataPoint.xy * 2.0 - 1.0;  // transforming coords from [0, 1] to [-1, 1]
                        float value = dataPoint.z * u_maxValue;  // transforming value from [0, 1] to [0, maxValue]

                        float d = distance(v_position, coords);
                        float w = 1.0 / pow(d, u_power);
                        valSum += value * w;
                        wSum += w;
                        if (d < minD) {
                            minD = d;
                        }
                    }
                }
                float interpolatedValue = valSum / wSum;
                float alpha = 1.0;
                if (minD > u_maxDistance) {
                    alpha = 0.0;
                }
                vec4 color = vec4(interpolatedValue / u_maxValue, 0.0, 0.0, alpha);

                gl_FragColor = color;
            }
        `);
    const viewPort = rectangleE(2, 2);
    const inverseDistanceShader = new Shader(inverseDistanceProgram, [
        new Attribute(gl, inverseDistanceProgram, 'a_position', viewPort.vertices),
        new Attribute(gl, inverseDistanceProgram, 'a_texturePosition', viewPort.texturePositions)
    ], [
        new Uniform(gl, inverseDistanceProgram, 'u_power', 'float', [power]),
        new Uniform(gl, inverseDistanceProgram, 'u_nrDataPoints', 'int', [observationsBbox.length]),
        new Uniform(gl, inverseDistanceProgram, 'u_maxValue', 'float', [maxValue]),
        new Uniform(gl, inverseDistanceProgram, 'u_maxDistance', 'float', [maxEdgeLengthBbox])
    ], [
        new DataTexture(gl, inverseDistanceProgram, 'u_dataTexture', [observationsBbox], 0)
    ], new Index(gl, viewPort.vertexIndices));
    return inverseDistanceShader;
};
const createColorizationShader = (gl, colorRamp, maxVal, smooth, valueFb) => {
    const maxColorRampValues = 15;
    const colorizationProgram = new Program(gl, `
            precision mediump float;
            attribute vec2 a_position;
            attribute vec2 a_textureCoord;
            varying vec2 v_textureCoord;

            void main() {
                v_textureCoord = a_textureCoord;
                gl_Position = vec4(a_position.xy, 0.0, 1.0);
            }
        `, `
            precision mediump float;
            uniform float u_colorRampValues[${maxColorRampValues}];
            uniform vec3 u_colorRampColors[${maxColorRampValues}];
            uniform int u_nrColorRampValues;
            uniform float u_maxValue;
            uniform bool u_smooth;
            uniform sampler2D u_valueTexture;
            varying vec2 v_textureCoord;

            vec3 valueToSmoothColor(in float value) {
                if (value < u_colorRampValues[0]) {
                    return u_colorRampColors[0];
                }
                for (int i = 1; i < ${maxColorRampValues}; i++) {
                    if (i > u_nrColorRampValues) {
                        break;
                    }
                    if (value < u_colorRampValues[i]) {
                        float alpha = (value - u_colorRampValues[i-1]) / (u_colorRampValues[i] - u_colorRampValues[i-1]);
                        vec3 color = alpha * (u_colorRampColors[i] - u_colorRampColors[i-1]) + u_colorRampColors[i-1];
                        return color;
                    }
                    if (i == u_nrColorRampValues) {
                        return u_colorRampColors[i];
                    }
                }
            }

            vec3 valueToStepColor(in float value) {
                for (int i = 0; i < ${maxColorRampValues}; i++) {
                    if (i > u_nrColorRampValues) {
                        break;
                    }
                    if (value < u_colorRampValues[i]) {
                        return u_colorRampColors[i];
                    }
                    if (i == u_nrColorRampValues) {
                        return u_colorRampColors[i];
                    }
                }
            }

            void main() {
                vec4 pixelData = texture2D(u_valueTexture, v_textureCoord);
                float val = pixelData.r * u_maxValue;
                float alpha = pixelData.w;
                vec3 rgb = vec3(0.0, 0.0, 0.0);
                if (alpha > 0.01) {
                    if (u_smooth) {
                        rgb = valueToSmoothColor(val);
                    } else {
                        rgb = valueToStepColor(val);
                    }
                }
                gl_FragColor = vec4(rgb.x / 255.0, rgb.y / 255.0, rgb.z / 255.0, alpha);
            }
        `);
    const colorizationShader = new Shader(colorizationProgram, [
        new Attribute(gl, colorizationProgram, 'a_position', rectangleA(2.0, 2.0).vertices),
        new Attribute(gl, colorizationProgram, 'a_textureCoord', rectangleA(2.0, 2.0).texturePositions)
    ], [
        new Uniform(gl, colorizationProgram, 'u_colorRampValues', 'float[]', colorRamp.map(e => e.val)),
        new Uniform(gl, colorizationProgram, 'u_colorRampColors', 'vec3[]', flattenRecursive(colorRamp.map(e => e.rgb))),
        new Uniform(gl, colorizationProgram, 'u_nrColorRampValues', 'int', [colorRamp.length]),
        new Uniform(gl, colorizationProgram, 'u_maxValue', 'float', [maxVal]),
        new Uniform(gl, colorizationProgram, 'u_smooth', 'bool', [smooth ? 1 : 0]),
    ], [
        new Texture(gl, colorizationProgram, 'u_valueTexture', valueFb.fbo.texture, 0)
    ]);
    return colorizationShader;
};
const createArrangementShader = (gl, world2pix, pix2clip, bbox, colorFb) => {
    const arrangementProgram = new Program(gl, `
            precision mediump float;
            attribute vec3 a_pos;
            attribute vec2 a_posTexture;
            uniform mat3 u_world2pix;
            uniform mat3 u_pix2clip;
            uniform vec4 u_bbox;
            varying vec2 v_posTexture;

            vec2 clipBbx2worldCoords(vec2 clipCoords, vec4 bbox) {
                float xPerct = ( clipCoords.x + 1.0 ) / 2.0;
                float yPerct = ( clipCoords.y + 1.0 ) / 2.0;
                float xWorld = xPerct * (bbox.z - bbox.x) + bbox.x;
                float yWorld = yPerct * (bbox.w - bbox.y) + bbox.y;
                return vec2(xWorld, yWorld);
            }

            void main() {
                v_posTexture = a_posTexture;
                vec2 worldPos = clipBbx2worldCoords(a_pos.xy, u_bbox);
                vec3 clipPos = u_pix2clip * u_world2pix * vec3(worldPos.xy, 1.0);
                gl_Position = vec4(clipPos.xy, 0.0, 1.0);
            }
        `, `
            precision mediump float;
            uniform sampler2D u_texture;
            varying vec2 v_posTexture;

            void main() {
                gl_FragColor = texture2D(u_texture, v_posTexture);
            }
        `);
    const arrangementShader = new Shader(arrangementProgram, [
        new Attribute(gl, arrangementProgram, 'a_pos', rectangleA(2, 2).vertices),
        new Attribute(gl, arrangementProgram, 'a_posTexture', rectangleA(2, 2).texturePositions),
    ], [
        new Uniform(gl, arrangementProgram, 'u_world2pix', 'mat3', flattenRecursive(world2pix)),
        new Uniform(gl, arrangementProgram, 'u_pix2clip', 'mat3', flattenRecursive(pix2clip)),
        new Uniform(gl, arrangementProgram, 'u_bbox', 'vec4', bbox)
    ], [
        new Texture(gl, arrangementProgram, 'u_texture', colorFb.fbo.texture, 0)
    ]);
    return arrangementShader;
};
const getBbox = (obs) => {
    const xs = obs.map(p => p[0]);
    const ys = obs.map(p => p[1]);
    const xMin = Math.min(...xs);
    const xMax = Math.max(...xs);
    const yMin = Math.min(...ys);
    const yMax = Math.max(...ys);
    return [xMin, yMin, xMax, yMax];
};
const zip = (arr0, arr1) => {
    const out = [];
    for (let i = 0; i < arr0.length; i++) {
        out.push(arr0[i].concat(arr1[i]));
    }
    return out;
};
const createDistanceMatrix = (coords) => {
    const matrix = createNDimArray([coords.length, coords.length]);
    for (let i = 0; i < coords.length; i++) {
        for (let j = i + 1; j < coords.length; j++) {
            const d = pointDistance(coords[i], coords[j]);
            matrix[i][j] = d;
            matrix[j][i] = d;
        }
    }
    return matrix;
};
const create7NearestNeighborsTextureData = (distanceMatrix, coords, values) => {
    const rows = nextPowerOf(values.length, 2);
    const data = createNDimArray([rows, 8, 4]);
    for (let r = 0; r < values.length; r++) {
        data[r][0] = [coords[r][0], coords[r][1], values[r], 255];
        const neighborIndices = getNIndicesSmallest(7, distanceMatrix[r]);
        for (let n = 1; n < 8; n++) {
            const ni = neighborIndices[n - 1];
            data[r][n] = [coords[ni][0], coords[ni][1], values[ni], 255];
        }
    }
    return data;
};
const pointDistance = (a, b) => {
    return Math.sqrt(Math.pow((a[0] - b[0]), 2) + Math.pow((a[1] - b[1]), 2));
};
const getNIndicesSmallest = (n, values) => {
    const smallest = getNSmallest(n, values);
    const indices = getIndicesInArray(smallest, values);
    return indices;
};
const getIndicesInArray = (pickedValues, allValues) => {
    return pickedValues.map(v => allValues.findIndex(a => a === v));
};
const getNSmallest = (n, values) => {
    return values.sort(function (a, b) { return a - b; }).slice(0, n);
};

class WindFieldLayer extends VectorLayer {
    constructor(options) {
        super(options);
    }
    createRenderer() {
        return new ParticleRenderer(this);
    }
    startAnimation(fps) {
        // @ts-ignore
        this.getRenderer().startAnimation(fps);
    }
}
/**
 * This renderer illustrates how WebGL can be used to to pixel-by-pixel calculations
 * that would be too expensive on a CPU but are easily done on a GPU.
 * In our shader we go through every pixel and calculate its new state from
 * its old state and that of it's environment.
 *
 * Note how similar in principle this is to Conway's Game of Life: one pixel's state is determined
 * by its surroundings from the time-step before.
 *
 * This renderer also illustrates another common technique in WebGL: `framebuffer-ping-pong`.
 * This is where the output of one shader is stored on a framebuffer and then passed to a subsequent shader.
 * With this, we can create a multi-step-pipeline, where each shader uses the previous
 * one's output as its own input.
 */
class ParticleRenderer extends LayerRenderer {
    constructor(layer) {
        super(layer);
        this.fps = 30;
        // setting up canvas
        const canvas = document.createElement('canvas');
        canvas.width = 1000;
        canvas.height = 1000;
        canvas.style.position = 'absolute';
        // preparing data
        const source = layer.getSource();
        const features = source.getFeatures();
        const aObservation = this.pointsToObservations(features);
        const gl = canvas.getContext('webgl');
        const rect = rectangleA(2.0, 2.0);
        // --------- Step 1: interpolating field between data points. ------------------------------------------
        const interpolProgram = new Program(gl, `
            attribute vec4 a_observation;
            uniform mat3 u_world2pix;
            uniform mat3 u_pix2canv;
            varying vec2 v_value;

            void main() {
                vec3 pixelPosition = u_world2pix * vec3(a_observation.x, a_observation.y, 1.);
                vec3 canvasPosition = u_pix2canv * pixelPosition;
                v_value = (a_observation.zw / 2.0) + 0.5;
                gl_Position = vec4(canvasPosition.xy, 0.0, 1.0);
            }
        `, `
            precision mediump float;
            varying vec2 v_value;

            void main() {
                gl_FragColor = vec4(v_value.xy, 0.0, 1.0);
            }
        `);
        const interpolShader = new Shader(interpolProgram, [
            new Attribute(gl, interpolProgram, 'a_observation', aObservation)
        ], [
            new Uniform(gl, interpolProgram, 'u_world2pix', 'mat3', flattenRecursive([
                [1., 0., 0.],
                [0., 1., 0.],
                [0., 0., 1.]
            ])),
            new Uniform(gl, interpolProgram, 'u_pix2canv', 'mat3', flattenRecursive([
                [1. / (canvas.width / 2), 0., 0.],
                [0, -1. / (canvas.height / 2), 0.],
                [-1., 1., 1.]
            ]))
        ], []);
        const interpolFb = new Framebuffer(gl, canvas.width, canvas.height);
        // ------------------ Step 2: moving particles along force field ------------------------------------
        const particleFb1 = new Framebuffer(gl, canvas.width, canvas.height);
        const particleFb2 = new Framebuffer(gl, canvas.width, canvas.height);
        const particleProgram = new Program(gl, `
            attribute vec3 a_vertex;
            attribute vec2 a_textureCoord;
            varying vec2 v_textureCoord;
            void main() {
                v_textureCoord = a_textureCoord;
                gl_Position = vec4(a_vertex.xyz, 1.0);
            }
        `, `
        precision mediump float;
        uniform sampler2D u_forceTexture;
        uniform sampler2D u_particleTexture;
        uniform float u_deltaT;
        varying vec2 v_textureCoord;

        float rand(vec2 co){
            return fract(sin(dot(co.xy ,vec2(12.9898,78.233))) * 43758.5453);
        }

        void main() {
            // moving particles
            vec2 speed = ((texture2D(u_forceTexture, v_textureCoord) - 0.5 ) * 2.0).xy;
            vec2 samplePoint = v_textureCoord - speed * u_deltaT * 0.1;
            samplePoint = mod(samplePoint, 1.0);
            gl_FragColor = texture2D(u_particleTexture, samplePoint);

            // fade out
            float fadeRate = 0.95;
            if (gl_FragColor.x != 1.0) {
                vec4 lastColor = texture2D(u_particleTexture, v_textureCoord);
                vec4 fadedColor = vec4(lastColor.xyz * fadeRate, 1.0);
                gl_FragColor = fadedColor;
            }

            // spawn and die-off
            float spawnChance = 0.0005;
            float dieChance = 0.2;
            float randVal = rand(v_textureCoord * abs(sin(u_deltaT)) * 0.01);
            if (randVal > (1. - spawnChance)) {  // spawn
                gl_FragColor = vec4(1.0, 1.0, 1.0, 1.0);
            } if (randVal < dieChance) {   // die off
                gl_FragColor = vec4(0.0, 0.0, 0.0, 0.0);
            }

            // no particles outside texture
            if (texture2D(u_forceTexture, v_textureCoord) == vec4(0.0, 0.0, 0.0, 0.0)) {
                gl_FragColor = vec4(0.0, 0.0, 0.0, 0.0);
            }
        }
        `);
        const particleShader = new Shader(particleProgram, [
            new Attribute(gl, particleProgram, 'a_vertex', rect.vertices),
            new Attribute(gl, particleProgram, 'a_textureCoord', rect.texturePositions)
        ], [
            new Uniform(gl, particleProgram, 'u_deltaT', 'float', [0.01])
        ], [
            new Texture(gl, particleProgram, 'u_forceTexture', interpolFb.fbo.texture, 0),
            new Texture(gl, particleProgram, 'u_particleTexture', particleFb1.fbo.texture, 1)
        ]);
        // ------------------ Step 3: Mixing background-field and particles ------------------------------------
        const textureMixProgram = new Program(gl, `
            attribute vec3 a_vertex;
            attribute vec2 a_textureCoord;
            varying vec2 v_textureCoord;
            void main() {
                v_textureCoord = a_textureCoord;
                gl_Position = vec4(a_vertex.xyz, 1.0);
            }
        `, `
            precision mediump float;
            uniform sampler2D u_bgTexture;
            uniform sampler2D u_particleTexture;
            varying vec2 v_textureCoord;
            void main() {
                vec4 bgColor = texture2D(u_bgTexture, v_textureCoord);
                vec4 particleColor = texture2D(u_particleTexture, v_textureCoord);
                vec4 colorMix = max(particleColor, bgColor);
                gl_FragColor = colorMix;
            }
        `);
        const textureMixShader = new Shader(textureMixProgram, [
            new Attribute(gl, textureMixProgram, 'a_vertex', rect.vertices),
            new Attribute(gl, textureMixProgram, 'a_textureCoord', rect.texturePositions)
        ], [], [
            new Texture(gl, textureMixProgram, 'u_bgTexture', interpolFb.fbo.texture, 0),
            new Texture(gl, textureMixProgram, 'u_particleTexture', particleFb1.fbo.texture, 1)
        ]);
        // Setup
        interpolShader.bind(gl);
        interpolShader.render(gl, [0, 0, 0, 0], interpolFb.fbo);
        textureMixShader.bind(gl);
        textureMixShader.render(gl);
        particleShader.bind(gl);
        // making data available for later
        this.canvas = canvas;
        this.gl = gl;
        this.interpolationShader = interpolShader;
        this.particleShader = particleShader;
        this.textureMixShader = textureMixShader;
        this.interpolFb = interpolFb;
        this.particleFb1 = particleFb1;
        this.particleFb2 = particleFb2;
    }
    /**
     * We could also have just started the animation right in the constructor.
     * Instead we created a separate `startAnimation` function so that it can optionally be run outside angular's zone,
     * preventing it from firing too many change cycles.
     * We leave this decision to the user, however, because it is not an ol-renderers duty to handle any angular-logic.
     */
    startAnimation(fps) {
        this.fps = fps;
        // Animation loop
        let i = 0;
        let fbIn;
        let fbOut;
        renderLoop(this.fps, (deltaT) => {
            i += 1;
            // framebuffer ping-pong
            if (i % 2 === 1) {
                fbIn = this.particleFb1;
                fbOut = this.particleFb2;
            }
            else {
                fbIn = this.particleFb2;
                fbOut = this.particleFb1;
            }
            // particle shader
            this.particleShader.textures[1].texture = fbIn.fbo.texture;
            this.particleShader.updateUniformData(this.gl, 'u_deltaT', [deltaT]);
            this.particleShader.bind(this.gl);
            this.particleShader.render(this.gl, null, fbOut.fbo);
            // texture to output
            this.textureMixShader.textures[1].texture = fbOut.fbo.texture;
            this.textureMixShader.bind(this.gl);
            this.textureMixShader.render(this.gl);
        });
    }
    stopAnimation() {
        this.fps = 0;
    }
    prepareFrame(frameState) {
        const layerState = frameState.layerStatesArray[frameState.layerIndex];
        const size = frameState.size;
        const opacity = layerState.opacity;
        if (size[0] !== this.canvas.width || size[1] !== this.canvas.height) {
            this.canvas.width = size[0];
            this.canvas.height = size[1];
        }
        this.canvas.style.opacity = `${opacity}`;
        // update world2pix
        const c2pT = frameState.coordinateToPixelTransform;
        const worldToPixelTransform = [
            [c2pT[0], c2pT[1], 0.],
            [c2pT[2], c2pT[3], 0.],
            [c2pT[4], c2pT[5], 1.]
        ];
        this.interpolationShader.updateUniformData(this.gl, 'u_world2pix', flattenRecursive(worldToPixelTransform));
        // update pix2canvas
        const pix2canv = [
            [1. / (this.canvas.width / 2), 0., 0.],
            [0, -1. / (this.canvas.height / 2), 0.],
            [-1., 1., 1.]
        ];
        this.interpolationShader.updateUniformData(this.gl, 'u_pix2canv', flattenRecursive(pix2canv));
        // bind new data and render
        this.interpolationShader.bind(this.gl);
        this.interpolationShader.render(this.gl, [0, 0, 0, 0], this.interpolFb.fbo);
        return true;
    }
    renderFrame(frameState, target) {
        return this.canvas;
    }
    renderDeclutter(frameState) {
    }
    pointsToObservations(features) {
        const pointToObservation = (feature) => {
            const coords = feature.getGeometry().getCoordinates();
            const props = feature.getProperties();
            return [coords[0], coords[1], props.wind[0], props.wind[1]];
        };
        const coordinates = features.map(f => f.getGeometry().getCoordinates());
        const delauney = Delaunator.from(coordinates);
        const indices = delauney.triangles;
        const aObservations = [];
        for (const i of indices) {
            const o = pointToObservation(features[i]);
            aObservations.push(o);
        }
        return aObservations;
    }
}

/*
 * Public API Surface of utils-maps
 */

/**
 * Generated bundle index. Do not edit.
 */

export { Attribute, DataTexture, DtmImageRenderer, DtmLayer, Engine, Entity, Framebuffer, Index, InterpolationLayer, InterpolationRenderer, ParticleRenderer, Program, Shader, Texture, Uniform, WindFieldLayer, arrayToCanvas, bindBufferToAttribute, bindFramebuffer, bindIndexBuffer, bindOutputCanvasToFramebuffer, bindProgram, bindTextureToFramebuffer, bindTextureToUniform, bindValueToUniform, canvasToImage, clearBackground, compileShader, createDataTexture, createEmptyTexture, createFloatBuffer, createFramebuffer, createIndexBuffer, createShaderProgram, createTextCanvas, createTexture, displayImageOn, drawArray, drawElements, flattenLayers, getAttributeLocation, getCurrentFramebuffersPixels, getDebugInfo, getUniformLocation, mapToSingleCanvas, rectangleA, rectangleE, renderLoop, scaledMapToSingleCanvas, setup3dScene, simpleMapToCanvas, triangleA, triangleE, updateBufferData, updateTexture, updateViewPort };
//# sourceMappingURL=dlr-eoc-utils-maps.mjs.map
